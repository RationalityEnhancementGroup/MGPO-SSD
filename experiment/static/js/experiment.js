// Generated by CoffeeScript 2.4.1
// coffeelint: disable=max_line_length, indentation
var REPETITIONS, BONUS, COMPLETION_CODE, BLOCKS, PROLIFIC, CONDITION, DEBUG, DEMO, TRAINING_TRIALS, DEMO_TRIALS, MIN_TIME, N_TRIAL, PARAMS, RETURN_TIME, SCORE, SHOW_PARTICIPANT, SHOW_PARTICIPANT_DATA, STAGE, STAGE2, STRUCTURE_TEST, STRUCTURE_TRAINING, TALK, TRIALS_TEST, TRIALS_TRAINING, TUTOR_DEMO, number_trials, calculateBonus, condition, createStartButton, delay, tutor_level, getTestTrials, getTrainingTrials, initializeExperiment, loadTimeout, principle_only, psiturk, saveData, slowLoad, with_demo, with_practice, workerId;
// Early experiment termination
var EXCLUDE = false;
BLOCKS = void 0;

TRIALS_TRAINING = void 0;
TRIALS_FEEDBACK = void 0;
TRIALS_TEST = void 0;
FEEDBACK_STRUCTURE_TRAINING = void 0;

DEMO_TRIALS = void 0;

STRUCTURE_TEST = void 0;

STRUCTURE_TRAINING = void 0;

N_TRIAL = void 0;

SCORE = 0;

calculateBonus = void 0;

getTrainingTrials = void 0;

getTestTrials = void 0;

DEBUG = false;

TALK = false;

SHOW_PARTICIPANT = false;

STAGE = 1;

TUTOR_DEMO = false;

DEMO = true;

BONUS = 0;

REPETITIONS = 0;

// searchParams = new URLSearchParams(location.search)

// PROLIFIC = (searchParams.get('prolific') == 'true') || 
//   (searchParams.get('hitId') == null) || 
//   (searchParams.get('hitId') == 'prolific');


if (DEBUG) {
  console.log("X X X X X X X X X X X X X X X X X\n X X X X X DEBUG  MODE X X X X X\nX X X X X X X X X X X X X X X X X");
  condition = 0;
  workerId = ['debugV3Vl2'];
} else {
  console.log("# =============================== #\n# ========= NORMAL MODE ========= #\n# =============================== #");
  //condition = 3
  //condition = getRandomInt(3); //TODO 
  counterbalance = getRandomInt(100)
  condition = parseInt(prompt("Condition", "0")) 
}

if (mode === "{{ mode }}") {
  // Viewing experiment not through the PsiTurk server
  DEMO = true;
//  condition = getRandomInt(3);
  workerId = ['debugV3Vl2'];
}

CONDITION = parseInt(condition);
COUNTERBALANCE = parseInt(counterbalance)
SHOW_PARTICIPANT_DATA = false;

PARAMS = {
  inspectCost: 1,
  tau: 0,
  bonusRate: {
    0: 0.0064,
    1: 0.0042,
    2: 0.0056
  },
  maxBonus: 2,
  delay_hours: 24,
  delay_window: 12,
  branching: '2_36',
  non_hier_branching: '312',
  condition: CONDITION,
  param_cond: COUNTERBALANCE,
  startTime: Date(Date.now()),
  stage: 1,
  basepay: 1,
  test_bonus: 1.5,
  training_number_trials: 12,
  test_number_trials: 10,
  clickDisplayMode: "posteriorMean",
  moveDisplayMode: "posteriorMean",
};

tutor_level=0;

MIN_TIME = 7;

DEMO_BONUS = 0.0;

function getRandomInt(max) {
  return Math.floor(Math.random() * Math.floor(max));
}

console.log('condition', CONDITION);
console.log('counterbalance', COUNTERBALANCE)
console.log('mode', mode);

psiturk = new PsiTurk(uniqueId, adServerLoc, mode);

psiturk.recordUnstructuredData('start_time', PARAMS.startTime);

psiturk.recordUnstructuredData('condition_type', PARAMS.condition_type)

psiturk.recordUnstructuredData('condition', CONDITION);

psiturk.recordUnstructuredData('param_condition', COUNTERBALANCE);

delay = function(time, func) {
  return setTimeout(func, time);
};

slowLoad = function() {
  var ref;
  return (ref = $('slow-load')) != null ? ref.show() : void 0;
};

loadTimeout = delay(12000, slowLoad);

createStartButton = function() {
  if (DEBUG) {
    initializeExperiment();
    return;
  }
  document.getElementById("loader").style.display = "none";
  document.getElementById("successLoad").style.display = "block";
  document.getElementById("failLoad").style.display = "none";
  return $('#load-btn').click(initializeExperiment);
};

saveData = function() {
  return new Promise(function(resolve, reject) {
    var timeout;
    timeout = delay(10000, function() {
      return reject('timeout');
    });
    return psiturk.saveData({
      error: function() {
        clearTimeout(timeout);
        console.log('Error saving data!');
        return reject('error');
      },
      success: function() {
        clearTimeout(timeout);
        console.log('Data saved to psiturk server.');
        return resolve();
      }
    });
  });
};

$(window).resize(function() {
  return checkWindowSize(1200, 600, $('#jspsych-target')); // frederic
});

$(window).resize();

$(window).on('load', function() {
  // Load data and test connection to server.
  slowLoad = function() {
    var ref;
    return (ref = $('slow-load')) != null ? ref.show() : void 0;
  };
  loadTimeout = delay(12000, slowLoad);
  psiturk.preloadImages(['static/images/plane.png', 'static/images/full_tree.png', 'static/images/move_po.gif', 'static/images/click_po.gif', 'static/images/repeat_po.gif']); //'static/images/click.gif', 'static/images/move.gif',
  return delay(300, function() {
    var id;
    console.log('Loading data');
    if (PARAMS.variance) {
      id = `${PARAMS.branching}`;
    } else {
      id = `${PARAMS.branching}`;
    }

    if (DEBUG || TALK) {
      createStartButton();
      return clearTimeout(loadTimeout);
    } else {
      if (DEMO) {
        clearTimeout(loadTimeout);
        return delay(500, createStartButton);
      } else {
        console.log('Testing saveData');
        return saveData().then(function() {
          clearTimeout(loadTimeout);
          return delay(500, createStartButton);
        }).catch(function() {
          clearTimeout(loadTimeout);
          return $('#data-error').show();
        });
      }
    }
  });
});

createStartButton = function() {
  if (DEBUG || TALK) {
    initializeExperiment();
    return;
  }
  if (DEMO && !TUTOR_DEMO) {
    $('#jspsych-target').append("<div class='alert alert-info'>\n   To start the experiment click <b>Begin</b> below.\n</div>\n<div class='center'>\n  <button class='btn btn-primary btn-lg centered' id=\"Begin\">Begin</button>\n</div>");
    $('#Begin').click(function() {
      SHOW_PARTICIPANT = true;
      var PARAM_MAP = loadJson("static/json/params_dist.json");
      var param_cond = COUNTERBALANCE//getRandomInt(100); // TODO
      var param_str = param_cond < 10 ? "0" + param_cond: "" + param_cond
      PARAMS.inspectCost = PARAM_MAP[""+param_cond]["Cost"]
      PARAMS.tau = PARAM_MAP[""+param_cond]["Tau"]
      PARAMS.distance_offset_4_2 = PARAM_MAP[""+param_cond]["Distance_4_2"]
      PARAMS.distance_offset_2_2 = PARAM_MAP[""+param_cond]["Distance_2_2"]
      PARAMS.distance_offset_2_1 = PARAM_MAP[""+param_cond]["Distance_2_1"]
      PARAMS.distance_offset_1_1 = PARAM_MAP[""+param_cond]["Distance_1_1"]
      console.log("Condition" + CONDITION + ", " + param_cond + ": Tau " + PARAMS.tau +" and Cost " + PARAMS.inspectCost + " and offset " + PARAMS.distance_offset_4_2, PARAMS.distance_offset_2_2, PARAMS.distance_offset_2_1, PARAMS.distance_offset_1_1);

      STRUCTURE_4_2 = loadJson("static/json/4_60_json/4_60_structure.json");
      PO_STRUCTURE_4_2 = loadJson("static/json/4_60_json/4_60_po_structure.json");
      STRUCTURE_1_1 = loadJson("static/json/1_8_json/1_8_structure.json");
      PO_STRUCTURE_1_1 = loadJson("static/json/1_8_json/1_8_po_structure.json");
      STRUCTURE_2_1 = loadJson("static/json/2_16_json/2_16_structure.json");
      PO_STRUCTURE_2_1 = loadJson("static/json/2_16_json/2_16_po_structure.json");
      STRUCTURE_2_2 = loadJson("static/json/2_30_json/2_30_structure.json");
      PO_STRUCTURE_2_2 = loadJson("static/json/2_30_json/2_30_po_structure.json");

      TRIALS_4_2 = loadJson("static/json/4_60_json/" + param_str + "_" + PARAMS.inspectCost.toString().substring(2) + "_" + PARAMS.tau.toString().substring(2) + ".json");
      TRIALS_1_1 = loadJson("static/json/1_8_json/" + param_str + "_" + PARAMS.inspectCost.toString().substring(2) + "_" + PARAMS.tau.toString().substring(2) + ".json");
      TRIALS_2_1 = loadJson("static/json/2_16_json/" + param_str + "_" + PARAMS.inspectCost.toString().substring(2) + "_" + PARAMS.tau.toString().substring(2) + ".json");
      TRIALS_2_2 = loadJson("static/json/2_30_json/" + param_str + "_" + PARAMS.inspectCost.toString().substring(2) + "_" + PARAMS.tau.toString().substring(2) + ".json");

      //TRAINING_TRIALS = JSON.parse(JSON.stringify(TRIALS));
      //SINGLE_BLOCK_TRAINING_TRIALS = JSON.parse(JSON.stringify(SINGLE_BLOCK_TRIALS))
      console.log("Filepath: " + "static/json/4_60_json/" + param_str + "_" + PARAMS.inspectCost.toString().substring(2) + "_" + PARAMS.tau.toString().substring(2) + ".json")
      console.log('Demo trials loaded');
      COMPLETION_CODE = "23EB2255" // Prolific
      return initializeExperiment();
    });
  }
  $('#load-icon').hide();
  $('#slow-load').hide();
  $('#success-load').hide();
};

initializeExperiment = function() {
  var Block, MouselabBlock, experiment_timeline, img, instructions, prompt_resubmit, reprompt, save_data;
  $('#jspsych-target').html('');
  console.log('INITIALIZE EXPERIMENT');
  console.log(CONDITION);
  PLANNING_MESSAGE =  `<br>Planning:<br>Clicking on a node reveals its value for a $${PARAMS.inspectCost} fee.<br><br>Moving:<br>Press the number keys 1 to 4 to move to the next node as indicated by the numbers on the edges.<br>Try using the number keys on top of your keyboard if the numpad keys don't work.<br><br>Camera:<br>Use the mouse to drag the camera and the mousewheel to zoom in and out.<br>Press the reset position button to reset the camera.`;

  //  ============================== #
  //  ========= EXPERIMENT ========= #
  //  ============================== #

  final_survey = {
    type: 'survey-text',
    preamble: function() {
      return markdown("# Please answer the following questions:");
    },
    questions: ['At our lab, we believe that all HITs must be approved and that participants must get their specified pay. Therefore, we approve and pay everyone. But this affects the results of our experiments. So, could you please let us know if you followed the instructions and tried your best to get the maximum reward. <br><br> Please answer one of the following: <br> <b> No - I did not try my best to get the maximum score</b> and did not follow the instructions <br> <b> Yes - I tried my best to obtain the maximum score </b> and to follow the instructions. <br><br> We thank you for answering sincerely! (Please note that, even if you answer \'No\', it will not affect your pay in anyway. It will just enable us to do our experiment data analysis better.)<br>', 'What is your age?', 'What gender do you identify with?'],
    button: 'Finish'
  }

  finish_po = {
    type: 'survey-text',
    preamble: function() {
      BONUS = calculateBonus()
      return markdown(`# You have completed the experiment and scored a total of **${SCORE}**, resulting in a bonus payment of **${BONUS}**.
        \n\nPlease click on the **"Finish experiment"** button to see the **completion code** 
        \n\nThank you for participating! Hope you enjoyed!`);
    },
    blockName: "survey-3",
    questions: [
      {
        prompt: 'What is your age?', 
        name: "Age"
      },
      {
        prompt: 'What gender do you identify with?',
        name: "Gender"
      },
      {
        prompt: 'Did you experience any issues with the feedback the tutor gave you?',
        name: "Issues",
        rows: 3
      },
      {
        prompt: 'Any comments/feedback?',
        name: "Feedback",
        rows: 3
      }
    ],
    button_label: 'Finish experiment'
  }

  instructions_po = {
    type: 'instructions',
    show_clickable_nav: true,
    pages: function()
    {
      return [
        markdown(`<h1>Structure of the HIT</h1>\n\n
          In this HIT, you will participate in a psychology experiment. This experiment has three phases: \n\n
          **Instructions:** In this phase, you will be introduced to the experiment and will be given instructions about it.\n\n
          **Training:** In this phase, you will learn how to play the game.\n\n
          **Test:** In this phase, you will be tested on what you learnt in the training phase.`), 
        markdown(`<h1>Flight Planning </h1>\n\n
          In this HIT, you will be playing a game called **Flight Planning**.\n\n
          During the game, you will navigate an airplane across a network of airports.\n\n
          Each airport has an underlying value that tells you **how much money the airline makes or loses** by operating that flight.\n\n
          When you land on an airport, its value is revealed and added to your score.\n\n
          Your goal in this game is to reach one of the final airports while making the most money possible.\n\n
          <img class='display' style=\"width:90%; height:auto\" src='static/images/full_tree.png'/>`), 
        markdown(`<h1>Planning</h1>\n\n
          It is hard to decide which airport to fly to when you don't know the profits.\n\n
          Fortunately, you can **click on a node** to reveal an estimate of the the underlying rewards.\n\n
          Every time you click on a node, you ask a different person who had a similar experience in the past for their **estimate** of the reward.\n\n
          Planning isn't free: **Each click costs $${PARAMS.inspectCost}**.\n\n\n\n
          <img class='display' style=\"width:90%; height:auto\" src='static/images/click_po.gif'/>`), 
        markdown(`<h1>Planning</h1>\n\n
          The advice you get won't always estimate the profits correctly.\n\n
          To get a better understanding of the profit, you can **repeat** clicking on a node to ask additional people for estimates.\n\n
          Don't ask for too much advice, each additional click still costs **$${PARAMS.inspectCost}**.\n\n\n\n
          <img class='display' style=\"width:90%; height:auto\" src='static/images/repeat_po.gif'/>`),
        markdown(`<h1>Moving</h1>\n\n To move the airplane, use the number keys **1 to 4**.\n\n
          When visiting a node, you will always reveal and receive its actual profit value - **no matter what the experts said**.\n\n
          After starting to move, it is no longer possible to click nodes to see their value so **make sure to plan ahead before moving**.\n\n
          **Note:** The key for each possible movement is indicated in the arrows connecting the nodes. Not all movement options are available at every node.\n\n
          <img class='display' style=\"width:90%; height:auto\" src='static/images/move_po.gif'/>`), 
        markdown(`<h1>Important Information</h1>\n\n
          There are a few things that should be kept in mind: \n\n
          You will play multiple rounds of the game.\n\n
          In each round, the rewards of the airports are **randomized**.\n\n
          You have to spend **at least** **7 seconds** on each round\n\n
          Since the test environment is quite large, you won't be able to see the whole environment at once. Use the **mouse** to move the whole environment by clicking and dragging.\n\n
          Additionally, use the **mouse wheel** to zoom in and out.`)
      ]}
  }

  instructions_po_posterior = {
    type: 'instructions',
    show_clickable_nav: true,
    pages: function()
    {
      return [
        markdown("<h1>Structure of the HIT</h1>\n\n"+
          "In this HIT, you will participate in a psychology experiment. This experiment has three phases:\n\n"+
          "**Instructions:** In this phase, you will be introduced to the experiment and will be given instructions about it.\n\n"+
          "**Training:** In this phase, you will learn how to play the game.\n\n"+
          "**Test:** In this phase, you will be tested on what you learnt in the training phase."), 
        markdown("<h1>Flight Planning </h1>\n\n"+
          "In this HIT, you will be playing a game called **Flight Planning**.\n\n"+
          "During the game, you will plan a trade route for an airline.\n\n"+
          "Each airport has an underlying value that tells you **how much money the airline will make or lose** by flying to that airport.\n\n"+
          "Your goal in this game is to select a route to one of the final airports that will make the most profit.\n\n"+
          `<img class='display' style=\"width:90%; height:auto\" src='static/images/full_tree.png'/>`), 
        markdown("<h1>Planning</h1>\n\n"+
          "It is hard to decide which airport to fly to when you don't know the profits.\n\n"+
          "Fortunately, you can **click on a node** to reveal an estimate of the the underlying rewards.\n\n"+
          "Every time you click on a node, you ask a different person who had a similar experience in the past for their **estimate** of the reward.\n\n"+
          `Planning isn't free: **Each click costs $${PARAMS.inspectCost}**.\n\n`+
          `<img class='display' style=\"width:90%; height:auto\" src='static/images/click_po.gif'/>`), 
        markdown("<h1>Planning</h1>\n\n"+
          "The advice you get won't always estimate the profits correctly.\n\n"+
          "To get a better understanding of the profit, you can **repeat** clicking on a node to ask additional people for estimates.\n\n"+
          "The node's value will update automatically, showing the current estimated profit taking all available information into account.\n\n"+
          `Don't ask for too much advice, each additional click still costs **$${PARAMS.inspectCost}**.\n\n`+
          `<img class='display' style=\"width:90%; height:auto\" src='static/images/repeat_po.gif'/>`),
        markdown("<h1>Moving</h1>\n\n"+
          "To decide on a route, move the airplane with the number keys **1 to 4**.\n\n"+
          "For each airport on the route, you will receive the estimated reward the airline will make.\n\n"+
          "After starting to move, it is no longer possible to click nodes to see their value so **make sure to plan ahead before moving**.\n\n"+
          "**Note:** The key for each possible movement is indicated in the arrows connecting the nodes. Not all movement options are available at every node.\n\n"+
          `<img class='display' style=\"width:90%; height:auto\" src='static/images/move_po.gif'/>`), 
        markdown("<h1>Important Information</h1>\n\n"+
          "There are a few things that should be kept in mind: \n\n"+
          "You will play multiple rounds of the game.\n\n"+
          "In each round, the rewards of the airports are **randomized**.\n\n"+
          "You have to spend **at least** **7 seconds** on each round.\n\n"+
          "Since the test environment is quite large, you won't be able to see the whole environment at once.\n\n"+
          "Use the **mouse** to move the whole environment by clicking and dragging.\n\n"+
          "Additionally, use the **mouse wheel** to zoom in and out.")
      ]}
  }

  quiz_po_posterior = {
    preamble: function() {
      return markdown(`<h1>Quiz</h1>Please answer the following questions about the *Flight Planning* game.<br>You have a total of 3 attempts to pass this comprehension quiz.<br>To review the instructions, click the "Show instructions" button. Questions marked with (*) are compulsory. <br><br>
        <a class="btn btn-primary collapsed" data-toggle="collapse" href="#collapseExample" role="button" aria-expanded="false" aria-controls="collapseExample">
          <span class="if-collapsed">Show instructions</span>
          <span class="if-not-collapsed">Hide instructions</span>
        </a>
        <div class="collapse" id="collapseExample" style="width:800px;text-align:left;margin: 0 auto;"><ul>
          <li>In this HIT, you will be playing a game called **Flight Planning**.</li>
          <li>During the game, you will plan a trade route for an airline.</li>
          <li>Each airport has an underlying value that tells you **how much money the airline will make or lose** by flying to that airport.</li>
          <li>Every time you click on a node, you ask a different person who had a similar experience in the past for their **estimate** of the reward.</li>
          <li>Your goal in this game is to select a route to one of the final airports that will make the most profit.</li>
          <li>It is hard to decide which airport to fly to when you don't know the profits.</li>
          <li>Fortunately, you can **click on a node** to reveal an estimate of the the underlying rewards.</li>
          <li>Every time you click on a node, you ask a different person who had a similar experience in the past for their **estimate** of the reward.</li>
          <li>Planning isn't free: **Each click costs $${PARAMS.inspectCost}**.</li>
          <li>The advice you get won't always estimate the profits correctly.</li>
          <li>To get a better understanding of the profit, you can **repeat** clicking on a node to ask additional people for estimates.</li>
          <li>Don't ask for too much advice, each additional click still costs **$${PARAMS.inspectCost}**.</li>
          <li>To move the airplane, use the number keys **1 to 4**.</li>
          <li>When visiting a node, you will receive the estimated reward the airplane will make when using the route.</li>
          <li>After starting to move, it is no longer possible to click nodes to see their value so **make sure to plan ahead before moving**.</li>
          <li>The key for each possible movement is indicated in the arrows connecting the nodes. Not all movement options are available at every node.</li>
          <li>You will play multiple rounds of the game. In each round, the rewards of the airports are **randomized**.</li>
        </ul></div>
        `);
    },
    type: 'survey-multi-choice',
    blockName: "survey-1",
    questions: [
      {
        prompt: "What do the numbers on the edges represent?",
        options: ['The cost of moving along the path', 'The key to move along the path', 'The numbers are irrelevant'],
        horizontal: false,
        required: true
      }, 
      {
        prompt: "What is the cost of clicking on a node to ask for advice?",
        options: ['$0', `$${PARAMS.inspectCost}`, '$5', '$1'],
        horizontal: false,
        required: true
      },
      {
        prompt: "Will each round be the same?",
        options: ['Yes', 'No, rewards of the airports are randomized', 'No, the flight paths connecting the airports are randomized'],
        horizontal: false,
        required: true
      }, 
      {
        prompt: "When clicking a node, what does the revealed value represent?",
        options: ["The exact profit I will make by visiting that node", "The current estimate of the profit I can make by visiting that node", "The cost of clicking the node again"],
        horizontal: false,
        required: true
      },
      {
        prompt: "Can a node be clicked multiple times?",
        options: ["Yes", "No"],
        horizontal: false,
        required: true
      }
    ],
    data: {
      correct: {
        Q0: 'The key to move along the path',
        Q1: `$${PARAMS.inspectCost}`,
        Q2: 'No, rewards of the airports are randomized',
        Q3: "The current estimate of the profit I can make by visiting that node",
        Q4: "Yes"
      }
    }
  }

  instruct_loop_po_posterior = {
    timeline: [instructions_po_posterior, quiz_po_posterior],
    loop_function: function(data) {
      var resp_id, response, responses;
      responses = data.last(1).values()[0].response; // TODO make index invariant
      for (resp_id in responses) {
        response = responses[resp_id];
        if (!(data.last(1).values()[0].correct[resp_id] === response)) {
          REPETITIONS += 1;
          psiturk.recordUnstructuredData('quiz_failures', REPETITIONS);
          psiturk.saveData();
          if(REPETITIONS >= 3){
            $('#jspsych-target').html(`<h1>Please return your submission</h1>\n<p>\nThank you for your interest in this study. 
              However, it is crucial that you understand these instructions to take part, and our data indicate that this is not the case. 
              I'm afraid you cannot proceed further in the experiment as a result. 
              Please return your submission on Prolific now by selecting the "Stop without completing" button, to avoid receiving a rejection.`);
            return false
          }
          else{
            alert(`You got at least one question wrong. We'll send you back to the instructions and then you can try again.`);
            return true; // try again
          }
        }
      }
      psiturk.recordUnstructuredData('quiz_failures', REPETITIONS);
      psiturk.finishInstructions();
      psiturk.saveData();
      return false;
    }
  }

  quiz_po = {
    preamble: function() {
      return markdown(`<h1>Quiz</h1>Please answer the following questions about the *Flight Planning* game. Questions marked with (*) are compulsory. <br><br>
        <a class="btn btn-primary collapsed" data-toggle="collapse" href="#collapseExample" role="button" aria-expanded="false" aria-controls="collapseExample">
          <span class="if-collapsed">Show instructions</span>
          <span class="if-not-collapsed">Hide instructions</span>
        </a>
        <div class="collapse" id="collapseExample" style="width:800px;text-align:left;margin: 0 auto;"><ul>
          <li>In this HIT, you will be playing a game called **Flight Planning**.</li>
          <li>During the game, you will navigate an airplane across a network of airports.</li>
          <li>Each airport has an underlying value that tells you **how much money the airline makes or loses** by operating that flight.</li>
          <li>When you land on an airport, its value is revealed and added to your score.</li>
          <li>Your goal in this game is to reach one of the final airports while making the most money possible.</li>
          <li>It is hard to decide which airport to fly to when you don't know the profits.</li>
          <li>Fortunately, you can **click on a node** to reveal an estimate of the underlying rewards.</li>
          <li>Every time you click on a node, you ask a different person who had a similar experience in the past for their **estimate** of the reward.</li>
          <li>Planning isn't free: **Each click costs $${PARAMS.inspectCost}**.</li>
          <li>The advice you get won't always estimate the profits correctly.</li>
          <li>To get a better understanding of the profit, you can **repeat** clicking on a node to ask additional people for estimates.</li>
          <li>Don't ask for too much advice, each additional click still costs **$${PARAMS.inspectCost}**.</li>
          <li>To move the airplane, use the number keys **1 to 4**.</li>
          <li>When visiting a node, you will always reveal and receive its actual profit value - **no matter what the experts said**.</li>
          <li>After starting to move, it is no longer possible to click nodes to see their value so **make sure to plan ahead before moving**.</li>
          <li>The key for each possible movement is indicated in the arrows connecting the nodes. Not all movement options are available at every node.</li>
          <li>You will play multiple rounds of the game. In each round, the rewards of the airports are **randomized**.</li>
        </ul></div>
        `);
    },
    type: 'survey-multi-choice',
    blockName: "survey-1",
    questions: [
      {
        prompt: "What do the numbers on the edges represent?",
        options: ['The cost of moving along the path', 'The key to move along the path', 'The numbers are irrelevant'],
        horizontal: false,
        required: true
      }, 
      {
        prompt: "What is the cost of clicking on a node to ask for advice?",
        options: ['$0', `$${PARAMS.inspectCost}`, '$5', '$1'],
        horizontal: false,
        required: true
      },
      {
        prompt: "Will each round be the same?",
        options: ['Yes', 'No, rewards of the airports are randomized', 'No, the flight paths connecting the airports are randomized'],
        horizontal: false,
        required: true
      }, 
      {
        prompt: "When clicking a node, what does the revealed value represent?",
        options: ["The exact profit I will make by visiting that node", "A guess of the profits I can make by visiting that node", "The cost of clicking the node again"],
        horizontal: false,
        required: true
      },
      {
        prompt: "Can a node be clicked multiple times?",
        options: ["Yes", "No"],
        horizontal: false,
        required: true
      }
    ],
    data: {
      correct: {
        Q0: 'The key to move along the path',
        Q1: `$${PARAMS.inspectCost}`,
        Q2: 'No, rewards of the airports are randomized',
        Q3: "A guess of the profits I can make by visiting that node",
        Q4: "Yes"
      }
    }
  }

  instruct_loop_po = {
    timeline: [instructions_po, quiz_po],
    loop_function: function(data) {
      var resp_id, response, responses;
      responses = data.last(1).values()[0].response;
      for (resp_id in responses) {
        response = responses[resp_id];
        if (!(data.last(1).values()[0].correct[resp_id] === response)) {
          REPETITIONS += 1;
          if(REPETITIONS >= 3){
            $('#jspsych-target').html(`<h1>Please return your submission</h1>\n<p>\nThank you for your interest in this study. 
              However, it is crucial that you understand these instructions to take part, and our data indicate that this is not the case. 
              I'm afraid you cannot proceed further in the experiment as a result. 
              Please return your submission on Prolific now by selecting the "Stop without completing" button, to avoid receiving a rejection.`);
          }
          else{
            alert(`You got at least one question wrong. We'll send you back to the instructions and then you can try again.`);
            return true; // try again
          }
        }
      }
      psiturk.finishInstructions();
      psiturk.saveData();
      return false;
    }
  }

  training_instruction_po = {
    type: 'instructions',
    show_clickable_nav: true,
    pages: function(){
      SCORE = 0;
      return [markdown(`<h1> Training section</h1>
        \n\nNow, you can get a feeling for the environment by practicing in training trials.
        \n\nYou will train in 4 different environments which will get progressively more difficult. In the later test trials, only the largest environment will be used.
        \n\nFor each environment, you will play 3 rounds.
        \n\nYour performance in this section is **not relevant** for your final bonus.
        \n\nRemember, you can use the node inspector **multiple times** to get estimates of the potential profits of a node and the number keys **1 to 4** to move. \n`)];//\n Since the test environment is quite large, you won't be able to see the whole environment at once. Use the **mouse** to move the whole environment by clicking and dragging. Additionally, use the **mouse wheel** to zoom in and out.\n")];
    }
  }

  demo_instruction_po_feedback = {
    type: 'instructions',
    show_clickable_nav: true,
    pages: function(){
      SCORE = 0;
      return [markdown("<h1> Training section</h1>\n\nIn this section you will observe an expert planning routes.\n\n You don't have to click any nodes, just observe the action of the expert and try to get an understanding of the used strategy.\n\nWhen the experts clicks the same node multiple it can be hard to see the changes. Pay attention to the number of the node the camera centers on.  \n")];//\n Since the test environment is quite large, you won't be able to see the whole environment at once. Use the **mouse** to move the whole environment by clicking and dragging. Additionally, use the **mouse wheel** to zoom in and out.\n")];
    }
  }

  training_instruction_po_feedback = {
    type: 'instructions',
    show_clickable_nav: true,
    pages: function(){
      SCORE = 0;
      return [markdown(`<h1> Training section</h1>
        \n\nNow, you can practice planning in the environment by training with an interactive tutor that will give you feedback on your planning actions.
        \n\nYou will train in 4 different environments which will get progressively more difficult. In the later test trials, only the largest environment will be used.
        \n\nFor each environment, you will play 3 rounds.
        \n\nYour performance in this section is **not relevant** for your final bonus. 
        \n\n Remember, you can use the node inspector **multiple times** to get estimates of the potential profits of a node and the number keys **1 to 4** to move. \n`)];//\n Since the test environment is quite large, you won't be able to see the whole environment at once. Use the **mouse** to move the whole environment by clicking and dragging. Additionally, use the **mouse wheel** to zoom in and out.\n")];
    }
  }

  training_instruction_po_choice = {
    type: 'instructions',
    show_clickable_nav: true,
    pages: function(){
      SCORE = 0;
      return [markdown(`<h1> Training section</h1>
        \n\nNow, you can practice planning in the environment by watching video demonstrations and training with an interactive tutor.
        \n\nYou will train in 4 different environments which will get progressively more difficult. In the later test trials, only the largest environment will be used.
        \n\nFor each environment, you will first watch a single demonstration and then practice with the tutor for two trials.
        \n\nIn the demonstration trials, you can observe how an expert plains. Please don't leave the window and try to understand the used strategy.
        \n\nIn the tutor trials, the tutor will highlight **two or more choices** and your task will be to decide which of the choices is the best action in the current situation.
        \n\nAfter making a choice, the tutor will give you feedback on your selection and tell you the best choice.
        \n\nYou might need to move the camera around to see the highlighted choices.
        \n\nIn addition to the highlighted choices, there is always **the additional choice to stop planning** and move along one of the discovered paths.
        \n\nYour performance in this section is **not relevant** for your final bonus. 
        \n\nRemember, you can use the node inspector **multiple times** to get estimates of the potential profits of a node and the number keys **1 to 4** to move. \n`)];
    }
  }

  training_instruction_po_dummy = {
    type: 'instructions',
    show_clickable_nav: true,
    pages: function(){
      SCORE = 0;
      return [markdown(`<h1> Training section</h1>
        \n\nNow, you can practice planning in the environment by watching video demonstrations and training with an interactive tutor.
        \n\nYou will train in 4 different environments which will get progressively more difficult. In the later test trials, only the largest environment will be used.
        \n\nFor each environment, you will first watch a single demonstration and then practice with the tutor for two trials.
        \n\nIn the demonstration trials, you can observe the used planning strategy. Please don't leave the window during the demonstrations.
        \n\nIn the tutor trials, the tutor will always highlight **two choices** and your task will be to choose one of the highlighted actions.
        \n\nAfter making a choice, the tutor will give you feedback on your selection.
        \n\nYou might need to move the camera around to see the highlighted choices.
        \n\nYour task is to guess which of the available choices (or moving) is optimal in each step.
        \n\nYour performance in this section is **not relevant** for your final bonus. 
        \n\nRemember, you can use the node inspector **multiple times** to get estimates of the potential profits of a node and the number keys **1 to 4** to move. \n`)];
    }
  }

  test_instruction_po = {
    type: 'instructions',
    show_clickable_nav: true,
    pages: function(){
      SCORE = 0;
      return [markdown("<h1>Test section</h1>\n\n"+
        "Next, you will perform the complete route planning for 10 different environments on your own.\n\n"+
        `You can earn a **bonus payment** in this section: for every 10 points in your final score you will receive an additional payment of £${Math.round((PARAMS.bonusRate[CONDITION]*10 + Number.EPSILON) * 100) / 100}.\n\n`+
        "As before, you can use the node inspector **multiple times** to get estimates of the potential profits of a node and the number keys **1 to 4** to move.\n")];
      }
  }


  training_survey_po = {
    preamble: function() {
      return markdown("# Please answer the following questions honestly, they won't affect your pay in any way:");
    },
    button: 'Continue',
    blockName: "survey-2",
    type: 'survey-multi-choice',
    questions: [
      {
        prompt: "Was it necessary to click airports multiple times to achieve a high reward?",
        options: ["Yes", "No"],
        required: true,
        horizontal: false
      },
      {
        prompt: "Which airports should be clicked first?",
        options: ["Airports far from the starting airport", "Airports close to the starting airport", "It doesn't matter"],
        required: true,
        horizontal: false
      }, 
      {
        prompt: "How enjoyable was it to learn strategies in the training environments?",
        options: ["Not enjoyable", "Slightly enjoyable", "Very enjoyable"],
        required: true,
        horizontal: false
      },
      {
        prompt: "How useful do you think the training environments were for you to learn a good strategy?",
        options: ["Not useful", "Slightly useful", "Very useful"],
        required: true,
        horizontal: false
      },
      {
        prompt: "Have you participated in this type of planning experiment in the past?",
        options: ["Yes", "No"],
        required: true,
        horizontal: false
      },
      {
        prompt: "Did you try your best to achieve a high reward?",
        options: ["Yes", "No"],
        required: true,
        horizontal: false
      }
    ]
  }

  train_po_func = function(trials, structure, po_structure, initial_trial) {
    return {
      showImage:false,
      minTime: 7,
      show_feedback: false,
      blockName: "train_main",
      stateDisplay: 'click',
      clickDisplayMode: PARAMS.clickDisplayMode,
      moveDisplayMode: PARAMS.moveDisplayMode,
      env_structure: po_structure,
      panUser: true,
      stateClickCost: PARAMS.inspectCost,
      tau: PARAMS.tau,
      timeline: trials,
      startScore: 0,
      partialObservability: true,
      lowerMessage: PLANNING_MESSAGE,
      type: "mouselab-mdp",
      playerImage: 'static/images/plane.png',
      graph: structure.graph,
      layout: structure.layout,
      initial: structure.initial,
      number_trials: function() {return number_trials;},
      on_finish: function() {
        return number_trials[0] += 1;
      },
      on_timeline_start: function() {
        console.log("on load")
        return number_trials = [initial_trial, PARAMS.training_number_trials]
      }
    }
  }

  train_po_demo_func = function(trials, structure, po_structure, dummy_tutor, initial_trial, distance_cost, distance_offset) {
    return {
      showImage:false,
      minTime: 7,
      show_feedback: false,
      blockName: "train_main",
      stateDisplay: 'click',
      clickDisplayMode: PARAMS.clickDisplayMode,
      moveDisplayMode: PARAMS.moveDisplayMode,
      env_structure: po_structure,
      dummy_tutor: dummy_tutor,
      distanceCost: distance_cost,
      distance_offset: distance_offset,
      panDemo: true,
      poDemo: true,
      stateClickCost: PARAMS.inspectCost,
      tau: PARAMS.tau,
      timeline: trials,
      startScore: 0,
      partialObservability: true,
      lowerMessage: "<br>Please do not leave the current tab or the window during the demonstration.",
      type: "mouselab-mdp",
      playerImage: 'static/images/plane.png',
      graph: structure.graph,
      layout: structure.layout,
      initial: structure.initial,
      number_trials: function() {return number_trials;},
      on_finish: function() {
        return number_trials[0] += 1;
      },
      on_timeline_start: function() {
        console.log("on load")
        return number_trials = [initial_trial, PARAMS.training_number_trials]
      }
    }
  }

  train_po_choice_func = function(trials, structure, po_structure, initial_trial, distance_cost, distance_offset) {
    return {
      showImage:false,
      minTime: 7,
      show_feedback: true,
      blockName: "train_main",
      clickDisplayMode: PARAMS.clickDisplayMode,
      moveDisplayMode: PARAMS.moveDisplayMode,
      distanceCost: distance_cost,
      distance_offset: distance_offset,
      compute_binary_feedback: false,
      show_choice_options: true,
      env_structure: po_structure,
      stateDisplay: 'click',
      panUser: true,
      undo_move: false,
      stateClickCost: PARAMS.inspectCost,
      tau: PARAMS.tau,
      partialObservability: true,
      timeline: trials,
      startScore: 0,
      number_trials: function() {return number_trials;},
      tutor_level: function() {return tutor_level;}, // Wrap as function to allow dynamic difficulty
      on_finish: function(data) { 
        // Update trial index
        number_trials[0] += 1;
      },
      on_timeline_start: function() {
        tutor_level += 1
        return number_trials = [initial_trial, PARAMS.training_number_trials]
      },
      lowerMessage: PLANNING_MESSAGE,
      type: "mouselab-mdp",
      playerImage: 'static/images/plane.png',
      graph: structure.graph,
      layout: structure.layout,
      initial: structure.initial
    }
  }

  train_po_dummy_func = function(trials, structure, po_structure, initial_trial){
    return{
      showImage:false,
      minTime: 7,
      show_feedback: true,
      blockName: "train_main",
      clickDisplayMode: PARAMS.clickDisplayMode,
      moveDisplayMode: PARAMS.moveDisplayMode,
      compute_binary_feedback: false,
      show_choice_options: true,
      dummy_tutor: true,
      env_structure: po_structure,
      stateDisplay: 'click',
      panUser: true,
      undo_move: false,
      stateClickCost: PARAMS.inspectCost,
      tau: PARAMS.tau,
      partialObservability: true,
      timeline: trials,
      startScore: 0,
      number_trials: function() {return number_trials;},
      on_finish: function(data) { 
        // Update trial index
        number_trials[0] += 1;
      },
      on_timeline_start: function() {
        return number_trials = [initial_trial, PARAMS.training_number_trials]
      },
      lowerMessage: PLANNING_MESSAGE,
      type: "mouselab-mdp",
      playerImage: 'static/images/plane.png',
      graph: structure.graph,
      layout: structure.layout,
      initial: structure.initial
    }
  }

  test_po = {
    showImage:false,
    minTime: 7,
    show_feedback: false,
    blockName: "test_main",
    clickDisplayMode: PARAMS.clickDisplayMode,
    moveDisplayMode: PARAMS.moveDisplayMode,
    stateDisplay: 'click',
    panUser: true,
    stateClickCost: PARAMS.inspectCost,
    tau: PARAMS.tau,
    timeline: TRIALS_4_2.slice(10, 20),
    startScore: 0,
    partialObservability: true,
    lowerMessage: PLANNING_MESSAGE,
    type: "mouselab-mdp",
    playerImage: 'static/images/plane.png',
    env_structure: PO_STRUCTURE_4_2,
    graph: STRUCTURE_4_2.graph,
    layout: STRUCTURE_4_2.layout,
    initial: STRUCTURE_4_2.initial,
    number_trials: function() {return number_trials;},
    on_finish: function() {
      return number_trials[0] += 1;
    },
    on_timeline_start: function() {
      console.log("on load")
      return number_trials = [0, PARAMS.test_number_trials]
    }
  }

  experiment_timeline = (function() {
    var tl;
    tl = [];

    tl.push(instruct_loop_po_posterior)
    if(CONDITION == 1){ // feedback
      tl.push(training_instruction_po_choice)
      tl.push(train_po_demo_func(TRIALS_1_1.slice(0, 1), STRUCTURE_1_1, PO_STRUCTURE_1_1, dummy_tutor=false, initial_trial=0, distance_cost=false, distance_offset=0))
      tl.push(train_po_choice_func(TRIALS_1_1.slice(1, 3), STRUCTURE_1_1, PO_STRUCTURE_1_1, initial_trial=1, distance_cost=false, distance_offset=0))
      tl.push(train_po_demo_func(TRIALS_2_1.slice(0, 1), STRUCTURE_2_1, PO_STRUCTURE_2_1, dummy_tutor=false, initial_trial=3, distance_cost=false, distance_offset=0))
      tl.push(train_po_choice_func(TRIALS_2_1.slice(1, 3), STRUCTURE_2_1, PO_STRUCTURE_2_1, initial_trial=4, distance_cost=false, distance_offset=0))
      tl.push(train_po_demo_func(TRIALS_2_2.slice(0, 1), STRUCTURE_2_2, PO_STRUCTURE_2_2, dummy_tutor=false, initial_trial=6, distance_cost=false, distance_offset=0))
      tl.push(train_po_choice_func(TRIALS_2_2.slice(1, 3), STRUCTURE_2_2, PO_STRUCTURE_2_2, initial_trial=7, distance_cost=false, distance_offset=0))
      tl.push(train_po_demo_func(TRIALS_4_2.slice(0, 1), STRUCTURE_4_2, PO_STRUCTURE_4_2, dummy_tutor=false, initial_trial=9, distance_cost=false, distance_offset=0))
      tl.push(train_po_choice_func(TRIALS_4_2.slice(1, 3), STRUCTURE_4_2, PO_STRUCTURE_4_2, initial_trial=10, distance_cost=false, distance_offset=0))
    }
    // else if(CONDITION == 1 || CONDITION == 2){ // distance cost feedback
    //   tl.push(training_instruction_po_choice)
    //   tl.push(train_po_demo_func(TRIALS_1_1.slice(0, 1), STRUCTURE_1_1, PO_STRUCTURE_1_1, dummy_tutor=false, initial_trial=0, distance_cost=true, distance_offset=PARAMS.distance_offset_1_1))
    //   tl.push(train_po_choice_func(TRIALS_1_1.slice(1, 3), STRUCTURE_1_1, PO_STRUCTURE_1_1, initial_trial=1, distance_cost=true, distance_offset=PARAMS.distance_offset_1_1))
    //   tl.push(train_po_demo_func(TRIALS_2_1.slice(0, 1), STRUCTURE_2_1, PO_STRUCTURE_2_1, dummy_tutor=false, initial_trial=3, distance_cost=true, distance_offset=PARAMS.distance_offset_2_1))
    //   tl.push(train_po_choice_func(TRIALS_2_1.slice(1, 3), STRUCTURE_2_1, PO_STRUCTURE_2_1, initial_trial=4, distance_cost=true, distance_offset=PARAMS.distance_offset_2_1))
    //   tl.push(train_po_demo_func(TRIALS_2_2.slice(0, 1), STRUCTURE_2_2, PO_STRUCTURE_2_2, dummy_tutor=false, initial_trial=6, distance_cost=true, distance_offset=PARAMS.distance_offset_2_2))
    //   tl.push(train_po_choice_func(TRIALS_2_2.slice(1, 3), STRUCTURE_2_2, PO_STRUCTURE_2_2, initial_trial=7, distance_cost=true, distance_offset=PARAMS.distance_offset_2_2))
    //   tl.push(train_po_demo_func(TRIALS_4_2.slice(0, 1), STRUCTURE_4_2, PO_STRUCTURE_4_2, dummy_tutor=false, initial_trial=9, distance_cost=true, distance_offset=PARAMS.distance_offset_4_2))
    //   tl.push(train_po_choice_func(TRIALS_4_2.slice(1, 3), STRUCTURE_4_2, PO_STRUCTURE_4_2, initial_trial=10, distance_cost=true, distance_offset=PARAMS.distance_offset_4_2))
    // }
    else if(CONDITION == 2){ // dummy feedback
      tl.push(training_instruction_po_dummy)
      tl.push(train_po_demo_func(TRIALS_1_1.slice(0, 1), STRUCTURE_1_1, PO_STRUCTURE_1_1, dummy_tutor=true, initial_trial=0, distance_cost=false, distance_offset=0))
      tl.push(train_po_dummy_func(TRIALS_1_1.slice(1, 3), STRUCTURE_1_1, PO_STRUCTURE_1_1, initial_trial=1))
      tl.push(train_po_demo_func(TRIALS_2_1.slice(0, 1), STRUCTURE_2_1, PO_STRUCTURE_2_1, dummy_tutor=true, initial_trial=3, distance_cost=false, distance_offset=0))
      tl.push(train_po_dummy_func(TRIALS_2_1.slice(1, 3), STRUCTURE_2_1, PO_STRUCTURE_2_1, initial_trial=4))
      tl.push(train_po_demo_func(TRIALS_2_2.slice(0, 1), STRUCTURE_2_2, PO_STRUCTURE_2_2, dummy_tutor=true, initial_trial=6, distance_cost=false, distance_offset=0))
      tl.push(train_po_dummy_func(TRIALS_2_2.slice(1, 3), STRUCTURE_2_2, PO_STRUCTURE_2_2, initial_trial=7))
      tl.push(train_po_demo_func(TRIALS_4_2.slice(0, 1), STRUCTURE_4_2, PO_STRUCTURE_4_2, dummy_tutor=true, initial_trial=9, distance_cost=false, distance_offset=0))
      tl.push(train_po_dummy_func(TRIALS_4_2.slice(1, 3), STRUCTURE_4_2, PO_STRUCTURE_4_2, initial_trial=10))
    }
    else if(CONDITION == 0){ // no feedback
      tl.push(training_instruction_po)
      tl.push(train_po_func(TRIALS_1_1.slice(0, 3), STRUCTURE_1_1, PO_STRUCTURE_1_1, initial_trial=0))
      tl.push(train_po_func(TRIALS_2_1.slice(0, 3), STRUCTURE_2_1, PO_STRUCTURE_2_1, initial_trial=3))
      tl.push(train_po_func(TRIALS_2_2.slice(0, 3), STRUCTURE_2_2, PO_STRUCTURE_2_2, initial_trial=6))
      tl.push(train_po_func(TRIALS_4_2.slice(0, 3), STRUCTURE_4_2, PO_STRUCTURE_4_2, initial_trial=9))
    }
    else{
      console.log("ERROR")
    }
    
    tl.push(test_instruction_po);
    tl.push(test_po);

    tl.push(training_survey_po);

    tl.push(finish_po);
    return tl;
  })();

  calculateBonus = function() {
    var bonus;
    console.log("Score", SCORE);
    bonus = SCORE * PARAMS.bonusRate[CONDITION];
    console.log(`Bonus: ${SCORE}*${PARAMS.bonusRate[CONDITION]}=${bonus}`)
    if(bonus > PARAMS.maxBonus)
    {
      bonus = PARAMS.maxBonus
    }
    bonus = (Math.round(bonus * 100)) / 100; // round to nearest cent
    return Math.min(Math.max(0, bonus), PARAMS.maxBonus);
  };
  reprompt = null;
  save_data = function() {
    return psiturk.saveData({
      success: function() {
        console.log('Data saved to psiturk server.');
        if (reprompt != null) {
          window.clearInterval(reprompt);
        }
        //return psiturk.computeBonus('compute_bonus', psiturk.completeHIT);
        psiturk.completeHIT();
      },
      error: function() {
        return prompt_resubmit;
      }
    });
  };
  prompt_resubmit = function() {
    $('#jspsych-target').html("<h1>Oops!</h1>\n<p>\nSomething went wrong submitting your HIT.\nThis might happen if you lose your internet connection.\nPress the button to resubmit.\n</p>\n<button id=\"resubmit\">Resubmit</button>");
    return $('#resubmit').click(function() {
      $('#jspsych-target').html('Trying to resubmit...');
      reprompt = window.setTimeout(prompt_resubmit, 10000);
      return save_data();
    });
  };
  return jsPsych.init({
    display_element: 'jspsych-target',
    timeline: experiment_timeline,
    // show_progress_bar: true
    on_finish: function() {
      if (DEBUG) {
        return jsPsych.data.displayData();
      } else {
        console.log('Finishing Experiment');
        psiturk.recordUnstructuredData('final_bonus', BONUS);
        psiturk.recordUnstructuredData('end_time', Date(Date.now()));
        return save_data();
      }
    },
    on_data_update: function(data) {
      console.log('data', data);
      return psiturk.recordTrialData(data);
    }
  });
};
